
=================
Linear Regression
=================
Regression is a statistical measurement used in finance, investing, and other disciplines that attempts to determine the strength of the relationship between one dependent variable and a series of other changing variables.

REGRESSION = strength of the relationship between depenedent and independent variables.

The two basic types of regressions are linear regression and multiple linear regression, although there are non-linear regression methods for more complicated data and analysis.

Linear Regression uses one independent variable to explain or predict the outcome of the dependent variable Y, while multiple regression uses two or more independent variables to predict the outcome.

Linear Regression: Y = a + bX + u

Multiple Regression: Y = a + b1X1 + b2X2 + b3X3 + ... + btXt + u  Where:

	Y = the variable that you are trying to predict (dependent variable).
	X = the variable that you are using to predict Y (independent variable).
	a = the intercept.
	b = the slope.
	u = the regression residual.

Regression Analysis is a form of predictive modelling technique which investigates the relationship between a dependent (target) and independent variable (predictor).
This technique is used for forecasting, time series modelling and finding the cause and effect relationship between the variables. 
For example, relationship between rash driving and number of road accidents by a driver is best studied through regression.

Regression analysis is an important tool for modelling and analyzing data.
Here, we fit a curve / line to the data points, in such a manner that the differences between the distances of data points from the curve or line is minimized.

There are multiple benefits of using regression analysis. They are as follows:
--> It indicates the significant relationships between dependent variable and independent variable.
--> It indicates the strength of impact of multiple independent variables on a dependent variable.



A linear regression is a linear approximation of a causal relationship between two or more variables.
Regression models are highly valuable, as they are one of the most common ways to make inferences and predictions.
There is a dependent variable, labeled Y, being predicted, and independent variables, labeled x1, x2, and so forth.
These are the predictors. Y is a function of the X variables, and the regression model is a linear approximation of this function.

The easiest regression model is the simple linear regression:
	Y = β0 + β1 * x1 + ε.
	where
	Y is the variable we are trying to predict and is called the dependent variable. X is an independent variable.
	There is a causal relationship between the two.
	β1 is the coefficient that stands before the independent variable.
	It quantitfies the effect of X on Y.
	The other two components are the constant β0 and the error – epsilon(ε).
	β0 is the y-intercept or bias.
	epsilon(ε) the error of estimation.
	The error is the actual difference between the observed income and the income the regression predicted.
	On average, across all observations, the error is 0.

In practice, we tend to use the linear regression equation.
It is simply ŷ = β0+ β1* x.
The ŷ here is referred to as y hat. Whenever we have a hat symbol, it is an estimated or predicted value.
B0  is the estimate of the regression constant β0. Whereas, b1 is the estimate of β1, and x is the sample data for the independent variable.

When we plot the data points on an x-y plane, the regression line is the best-fitting line through the data points.
The distance between the observed values and the regression line is the estimator of the error term epsilon. Its point estimate is called residual.



=======================
Model and Cost Function
=======================
To describe the supervised learning problem slightly more formally, our goal is, given a training set, to learn a function h : X → Y 
so that h(x) is a “good” predictor for the corresponding value of y.
For historical reasons, this function h is called a hypothesis.

Hypothesis function for Linear Regression : f(x) = mx + c or y = mx + c
	where m = coefficient of x and c is the intercept

When the target variable that we’re trying to predict is continuous, such as in our housing example, we call the learning problem a regression problem.
When y can take on only a small number of discrete values, we call it a classification problem.

We can measure the accuracy of our hypothesis function by using a cost function.
This takes an average difference (fancier version of an average) of all the results of the hypothesis with inputs from x's and the actual output y's.

Cost function(J) of Linear Regression is the Root Mean Squared Error (RMSE) between predicted y value (pred) and true y value (y).
	J = minimize(1/n SumOf((predicted_value - actual_value)^2))

To update m and c values in order to reduce Cost function (minimizing RMSE value) and achieving the best fit line the model uses Gradient Descent.
The idea is to start with random m and c values and then iteratively updating the values, reaching minimum cost.

A contour plot is a graph that contains many contour lines.
A contour line of a two variable function has a constant value at all points of the same line.

L2-Loss for a given example is called squared-error.
L2-Loss = square of the difference between prediction and label
		= (observation - prediction)^2

For our machine learning model, we are more interested for minimizing loss not only for one example but for the entire dataset.

A Univariate Linear Regression model depends on only one feature, but a more sophisticated model relies on multiple fearures, each having a separate weight associated with them.
For example, a model that relies on three features might look as follows:
	y = m1x1 + m2x2 + m3x3 + c

Mean square error (MSE) is the average squared loss per example over the whole dataset.
To calculate MSE, sum up all the squared losses for individual examples and then divide by the number of examples:
	MSE = (Sum of L2-Loss for the entire dataset)/(total number of examples)

#################################################
# mean squared error
mse = np.sum((y_pred - y_actual)**2)

# root mean squared error
# m is the number of training examples
rmse = np.sqrt(mse/m)
#################################################



================
Gradient Descent
================
Gradient Descent is the process of minimizing a function by following the gradients of the cost function.
This involves knowing the form of the cost as well as the derivative so that from a given point you know the gradient and can move in that direction.

So we have our hypothesis function and we have a way of measuring how well it fits into the data.
Now we need to estimate the parameters in the hypothesis function. That's where gradient descent comes in.

It is an optimization algorithm used to find the values of parameters (coefficients) of a function (f) that minimizes a cost function (cost).
It is best used when the parameters cannot be calculated analytically (using linear algebra) and must be searched for by an optimization algorithm.

Optimization is a big part of machine learning. Almost every machine learning algorithm has an optimization algorithm at it’s core.
Gradient descent is an optimization algorithm used to find the values of parameters (coefficients) of a function that minimizes a cost function.
The procedure starts off with initial values for the coefficient or coefficients for the function. These could be 0.0 or a small random value.
	coefficient = 0.0

The cost of the coefficients is evaluated by plugging them into the function and calculating the cost.
	cost = f(coefficient)
	or
	cost = evaluate(f(coefficient))

The derivative of the cost is calculated.
The derivative is a concept from calculus and refers to the slope of the function at a given point.
We need to know the slope so that we know the direction (sign) to move the coefficient values in order to get a lower cost on the next iteration.
	delta = derivative(cost)

Now that we know from the derivative which direction is downhill, we can now update the coefficient values.
A learning rate parameter (alpha) must be specified that controls how much the coefficients can change on each update.
	coefficient = coefficient – (alpha * delta)

This process is repeated until the cost of the coefficients (cost) is 0.0 or close enough to zero to be good enough.
It does require us to know the gradient of our cost function or the function we are optimizing, but besides that, it’s very straightforward.

The goal of all supervised machine learning algorithms is to best estimate a target function (f) that maps input data (X) onto output variables (Y).
This describes all classification and regression problems.



=========================
Iterative Approach for ML
=========================
There is an iterative trial-and-error process that machine learning algorithms use to train a model.
Here the model (Prediction Function) takes one or more features as input and returns one prediction as output.
Then suppose the same model has a Loss Function (Cost Function).
Now this cost function may be valid or invalid based on the difference of observation and actual result from the training data.
In order to get a better insight of the cost function, we have to calculate this for the entire dataset.
But calculating the cost function for every conceivable value over the entire data set would be an inefficient way of finding the convergence point.
Here comes the Gradient-Descent Function.

The first stage in gradient descent is to pick a starting value.
The starting point doesn't matter much; therefore, many algorithms simply set to 0 or pick a random value.
The gradient descent algorithm then calculates the gradient of the loss curve at the starting point.
When there are multiple weights, the gradient is a vector of partial derivatives with respect to the weights.
The gradient always points in the direction of steepest increase in the loss function.
The gradient descent algorithm takes a step in the direction of the negative gradient in order to reduce loss as quickly as possible.
To determine the next point along the loss function curve gradient descent algorithm adds some fraction of the gradient's magnitude to the starting point.
The gradient descent then repeats this process, edging ever closer to the minimum.

Gradient descent algorithms multiply the gradient by a scalar known as the learning rate (or step size) to determine the next point.
Hyperparameters are the knobs that programmers tweak in machine learning algorithms.
The "knobs" that we tweak during successive runs of training a model. For example, learning rate is a hyperparameter.
Most machine learning programmers spend a fair amount of time tuning the learning rate.

If we pick a learning rate that is too small, learning will take too long
Conversely, if we specify a learning rate that is too large, the next point will perpetually bounce haphazardly across the bottom of the well like a quantum mechanics experiment gone horribly wrong.



========================
Normal Data Distribution
========================
The probability density for the Gaussian distribution is
	p(x) = (1 / sqrt(2 * pi * sigma * sigma)) * (exp(-((x - mean) ^ 2)/(2 * sigma * sigma))
		where
		'mean' is the mean 
		'sigma' the standard deviation 
		The square of the standard deviation, 'sigma^2' or (sigma*sigma) is called the variance.

The function has its peak at the mean, and its “spread” increases with the standard deviation.
This implies that normal is more likely to return samples lying close to the mean, rather than those far away.

The Standard Normal curve has mean 0 and standard deviation 1.
If a dataset follows a normal distribution, then about 68% of the observations will fall within 'sigma' of the mean 'mean', which in this case is with the interval (-1,1). 
About 95% of the observations will fall within 2 standard deviations of the mean, which is the interval (-2,2) for the standard normal, and about 99.7% of the observations will fall within 3 standard deviations of the mean, which corresponds to the interval (-3,3) in this case.

Although it may appear as if a normal distribution does not include any values beyond a certain interval, the density is actually positive for all values between (-INF to +INF).

Data from any normal distribution may be transformed into data following the standard normal distribution by subtracting the mean  and dividing by the standard deviation 


